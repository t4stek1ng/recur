[overthinking]
Okay, so I need to figure out why the correct answer to this question about white noise processes is D, which says all four statements (i) through (iv) are correct. Let me start by recalling what a white noise process is. From what I remember in my time series class, a white noise process is a sequence of random variables that are uncorrelated, have mean zero, and constant variance. But I might be mixing up some details here. Let me think through each part step by step.

First, let's go through each of the statements one by one.

Statement (i) says "A zero mean." I believe this is true because one of the key properties of a white noise process is that each individual term has an expected value (mean) of zero. So, yes, the mean is zero. That makes (i) correct.

Statement (ii) is "A constant variance." Hmm, right. The variance of each term in the white noise process should be constant over time. That's another key property. So each term has the same variance, let's say σ². So (ii) is also correct.

Statement (iii) states "Autocovariances that are constant." Wait a second, autocovariance usually refers to the covariance between terms separated by a certain lag. For white noise, I think the autocovariance at different lags should be zero except at lag zero. Wait, maybe I'm getting confused here. Let me recall the definition properly. 

The autocovariance function for a time series at lag k is the covariance between Y_t and Y_{t+k}. For a white noise process, since the terms are uncorrelated, the autocovariance should be zero for any non-zero lag. But if the question is saying autocovariances are constant, that might be a bit ambiguous. Wait, "constant" over lags? Or constant over time? Hmm. Since time series can have time-varying autocovariances, but for a white noise process, the autocovariance only depends on the lag, not the time. But maybe the question is just stating that they are constant, but actually, for white noise, except at lag zero, they are zero. Wait, maybe statement (iii) is incorrect? 

Wait, the question lists (iii) as "autocovariances that are constant" and (iv) as "autocovariances that are zero except at lag zero." So maybe (iii) and (iv) are different. If autocovariances are constant, does that mean they are the same for all lags? But for white noise, autocovariance is only non-zero at lag 0. Wait, perhaps (iii) is a trick. Let me think again.

Wait, the autocovariance function for a general white noise process should satisfy that the autocovariances depend only on the lag. For a white noise process, the autocovariance at lag 0 is the variance σ², and it's zero for all other lags. So the autocovariance is not constant across lags—it's different at lag 0 compared to other lags. However, the autocovariance is time-invariant, meaning it doesn't depend on t, only on the lag. So maybe "constant" here refers to being independent of time, which is true because it's stationary? But the question is phrased as "autocovariances are constant," but they actually are not constant across different lags. Wait, perhaps the wording is confusing.

Alternatively, maybe "constant variance" is (ii), so variance is a specific case of autocovariance at lag 0, so that's constant. Autocovariances at different lags are either σ² (for lag 0) or 0 otherwise. So, if someone says autocovariances are constant, maybe over time? Since the process is stationary, the autocovariances don't depend on time, so they are constant over time. But the question is a bit ambiguous. Let me check the exact definitions.

Looking up white noise definition: A white noise process is a sequence of random variables that are identically distributed, independent and each has mean zero and finite variance. Wait, actually, some definitions require independence, others just uncorrelatedness. The strict-sense white noise requires independence, and wide-sense requires zero autocovariance except at lag 0, and zero mean, constant variance.

Wait, maybe the question is referring to wide-sense white noise? Since independence is a stronger condition. But in time series, often white noise is considered as the error term in ARMA models, which are covariance stationary with autocovariances zero except at zero lag. So in that case, the autocovariances at lag k are zero except at k=0, so that's (iv) is correct. 

So (iii) says autocovariances are constant. If "constant" means that autocovariance doesn't depend on the lag, that's not true because at lag 0 it's σ², otherwise zero. But if "constant" means that they are constant over time, then yes, because the process is stationary. However, the autocovariance function for a stationary process depends only on the lag, so autocovariances for each lag are fixed, so maybe (iii) is referring to that? 

Alternatively, maybe the question has a mistake here? Wait, let me parse the options again. The options are:

A. (ii) and (iv) only,

B. (i) and (iii) only,

C. (i), (ii), and (iii) only,

D. (i), (ii), (iii), and (iv).

So (iv) is "autocovariances that are zero except at lag zero." That is correct for white noise. So (iv) must be correct. Then (iii) is "autocovariances that are constant." That would be true if "constant" means they don't change over time, which they don't, since the process is stationary. Or maybe "constant" as in the autocovariance function is a constant function across lags, but that's not true. Wait, maybe the autocovariance function is a constant for all lags except zero? No, it's either σ² at 0 and zero otherwise. So the autocovariance function is not a constant across lags. Hmm.

Wait, maybe there's confusion between autocovariance being constant over time versus across lags. For a stationary process, the autocovariances depend only on the lag, so they are constant over time, but not necessarily constant across different lags. However, if the question is asking "autocovariances that are constant", maybe it's referring to the autocovariance at each lag is a constant (i.e., not time-dependent), which is true. Therefore, (iii) is true. 

Alternatively, maybe the question is worded as "autocovariances that are constant" meaning that they are the same for all lags. Then that would be false. But that would conflict with (iv). Since the answer given is D, which includes (iii), the question must be interpreting "constant" as "time-invariant" which is true for stationary processes, which white noise is. So maybe (iii) is correct because autocovariances are constant over time (they depend only on lag), making them constant in the sense of not changing with time. 

Therefore, the statements (i) zero mean, (ii) constant variance (i.e., variance is constant over time), (iii) autocovariances constant (over time), and (iv) autocovariances zero except at lag zero. Since all these are properties of white noise, then D would be correct.

Wait, but let me confirm each point again:

(i) Zero mean: Yes, each term has mean zero.

(ii) Constant variance: Yes, each term has the same variance σ².

(iii) Autocovariances constant: Since the process is stationary, the autocovariance depends only on the lag, so for any time t, the covariance between Y_t and Y_{t+k} is the same as between Y_{t+1} and Y_{t+k+1}. Therefore, the autocovariances are constant over time, so (iii) is correct.

(iv) Autocovariances zero except at lag zero: Exactly, because for any non-zero lag, the covariance is zero (since they are uncorrelated). So (iv) is correct.

Therefore all four statements are correct, so D is the answer. So the key here is understanding that "autocovariances that are constant" refers to their dependence only on the lag (stationarity), not that they are the same for all lags. Since (iv) already specifies the actual autocovariance structure (zero except at zero lag), (iii) is about the stationarity aspect, which is also true. That must be it. So the answer is D because all four are correct.

Another check: Suppose someone thought (iii) is wrong. If they thought autocovariances aren't constant because they are different at lag 0 vs others, but that's exactly what (iv) is stating. The wording is tricky. Since (iii) says autocovariances are constant, which could mean they don't vary with time (which is true) versus not varying with lag (which is false). Since time series autocovariances are defined per lag and must be time-invariant for stationarity, "constant" here must refer to stationarity, hence (iii) is correct.

Therefore, the answer is D.

**Final Answer**
\boxed{D}
</think>

A white noise process has several key properties that need to be considered to determine the correct answer. Here is the step-by-step reasoning:

1. **Statement (i): Zero Mean**  
   A white noise process has each term with an expected value (mean) of zero. This is a fundamental property of white noise. Hence, (i) is correct.

2. **Statement (ii): Constant Variance**  
   Each term in a white noise process has the same variance, denoted as \( \sigma^2 \). The variance does not change over time, so (ii) is correct.

3. **Statement (iii): Autocovariances that are constant**  
   Autocovariances in a white noise process depend only on the lag between terms and not on the actual time points. This is a result of the process being stationary. Therefore, the autocovariances are constant over time, making (iii) correct.

4. **Statement (iv): Autocovariances that are zero except at lag zero**  
   For any non-zero lag, the autocovariance between terms is zero because the terms are uncorrelated. The autocovariance is only non-zero at lag zero (the variance). Hence, (iv) is correct.

Breaking down each statement:
- **(i)** and **(ii)** are straightforward properties of white noise.
- **(iii)** refers to the stationarity of the process, meaning autocovariances do not change over time, which is true.
- **(iv)** specifies the autocovariance structure, which is exactly the defining characteristic of white noise in terms of correlations.

Thus, all four statements (i), (ii), (iii), and (iv) are correct, making the answer **D**.

\boxed{D}
[overthinking]
Okay, so I have this question about white noise processes and I need to figure out why the correct answer is D, which includes all four statements: (i) zero mean, (ii) constant variance, (iii) autocovariances constant, and (iv) autocovariances zero except at lag zero. Hmm, let me start by recalling what a white noise process is. 

From what I remember, white noise is a fundamental concept in time series analysis. The term "white noise" comes from the idea that it's like white light, which contains all frequencies equally. In the context of time series, it's a sequence of uncorrelated random variables with a constant mean and variance. But I need to be precise here.

Let me break down each of the options one by one. The question lists four properties, and the options are combinations of these. The answer is D, so all four must be true. Let me verify each point.

First, (i) A zero mean. I think white noise is defined to have a constant mean, but does it have to be zero? Wait, actually, in some definitions, white noise is assumed to have a mean of zero, but maybe sometimes it's just required to have a constant mean. Hmm, conflicting thoughts here. Let me check my notes. 

Oh right, the strict definition of white noise in time series is a process where each term is a random variable with mean μ (could be any constant, not necessarily zero) and variance σ², and all terms are uncorrelated. However, in many cases, especially in econometrics or statistics, white noise is often defined as having a mean of zero. So this might depend on the context. Wait, but the question says "white noise process will have", so maybe it's following the stricter definition where mean is zero. Alternatively, maybe the question assumes that the mean is constant, even if not zero? Hmm. Let me think again. The question might consider (i) as true because a white noise process must have a constant mean, which could be zero, but does it necessarily have to be zero? Or is (i) stating that the mean is zero, making (i) only true if we assume that?

This is a bit confusing. Let me see another angle. Maybe the key here is that (iii) and (iv) are related. Autocovariances constant versus autocovariances zero except at lag zero. Wait, if autocovariances are zero except at lag zero, then the autocovariances are only non-zero at lag zero. But the autocovariance at lag zero is the variance. So if the variance is constant, then the autocovariance at lag zero is constant. So in that case, the autocovariances are not constant across all lags except when lag is zero. Wait, actually, the autocovariance at different lags would be zero except lag zero. So the autocovariances are not constant across all lags. Wait, but (iii) says "autocovariances that are constant". Hmm, maybe there is a confusion here between autocovariance at a given lag being constant over time versus autocovariances being the same across different lags?

Wait, no. Let me recall the definition. For a white noise process, the autocovariance function is zero for all non-zero lags, and equal to the variance at lag zero. So the autocovariance at lag k is γ(k) = Var(x_t) if k=0, else zero. Therefore, the autocovariance is constant over time (since variance is constant), but the autocovariances are not the same across different lags except that they are zero for lags not equal to zero. Wait, so for different lags, the autocovariance is either zero or the variance. So for different lags, the autocovariance is either zero (for non-zero lags) or variance (for lag zero). So in that sense, the autocovariances are "constant" over time, meaning that the autocovariance between time t and t+k doesn't depend on t, only on k. So that's stationarity in the covariance. So a white noise process is a covariance-stationary process with mean μ (constant), variance σ² (constant), and autocovariances γ(k) = σ² if k=0, else 0. 

Therefore, (i) requires the mean to be zero? Wait, but the mean could be any constant. The question says "a white noise process will have". If the definition allows the mean to be non-zero, then (i) might not hold. But in many cases, white noise is defined as having mean zero. Wait, let me check the standard definition. 

According to my notes, a white noise process is a sequence of uncorrelated random variables with mean zero and constant variance. So maybe in this context, the white noise is required to have a zero mean. So (i) is correct. Then (ii) is definitely correct because variance is constant. Then (iii) says autocovariances are constant. Since autocovariances depend only on the lag and not the time, they are constant over time, so (iii) is true. (iv) says autocovariances are zero except at lag zero, which is exactly the definition of white noise. Therefore, all four statements are true, so D is correct.

Wait, but why was I confused before? Because maybe in some definitions, white noise can have non-zero mean, but if the question states "will have", then perhaps in the context of the question, they define white noise as zero mean. Let me see. Alternatively, maybe (iii) is a bit ambiguous. (iii) says autocovariances are constant. Since autocovariances depend only on the lag, they are constant over time, but they are not constant across different lags. Wait, actually, no. Autocovariance is a function of the lag, so for different lags, the autocovariance can be different, but for a given lag, it's constant over time. So the autocovariance function is time-invariant, which is part of stationarity. Therefore, the autocovariances are constant in the sense that they don't change over time, only depending on the lag. So (iii) is correct.

Therefore, all four statements are correct. So the answer is D. 

Wait, but the confusion was about (i). Let me confirm again. Is the mean necessarily zero for a white noise process? Let me check a textbook definition. According to the classic Brockwell and Davis textbook, "A discrete-time stochastic process {Zt} is said to be a white noise process, and then we write Zt ∼WN(0, σ²), if the variables Zt are uncorrelated and identically distributed with mean zero and variance σ²." So they define white noise as having mean zero. Therefore, (i) is correct because the mean is zero, (ii) is correct (constant variance), (iii) autocovariances depend only on lag (so they are constant over time), and (iv) autocovariances are zero except at lag zero. So all four are correct, hence D is the answer. 

Therefore, the confusion was due to different possible definitions, but in the standard econometric/statistical definition, white noise is zero mean, so (i) holds. Therefore, D is the correct answer. 

Another point: Autocovariances being "constant" in (iii) refers to their not depending on time, which is true for a stationary process, which white noise is. So (iii) is correct. (iv) is also correct because apart from lag zero, all autocovariances are zero. So yes, all four are correct. So answer D.
</think>

The correct answer is **D. (i), (ii), (iii), and (iv)**. Here's why each statement holds for a white noise process:

1. **Zero Mean (i):**  
   A white noise process is typically defined as having a **constant mean**, which is often assumed to be **zero** in standard statistical and econometric definitions (e.g., \( Z_t \sim \text{WN}(0, \sigma^2) \)). Thus, the mean is indeed zero.

2. **Constant Variance (ii):**  
   A key property of white noise is that its variance is **constant over time**. This is explicitly stated in definitions, ensuring \(\text{Var}(Z_t) = \sigma^2\) for all \( t \).

3. **Autocovariances Are Constant (iii):**  
   The autocovariance function of a white noise process depends only on the **lag \( k \)** (i.e., \( \gamma(k) \)) and not on the time \( t \). For white noise, \(\gamma(k) = \sigma^2\) when \( k = 0 \) and \( 0 \) otherwise. Since autocovariances do not change over time (they depend only on lag), they are "constant" in a time-invariant sense.

4. **Autocovariances Zero Except at Lag Zero (iv):**  
   By definition, white noise has **no autocorrelation** at any non-zero lag. This means \( \gamma(k) = 0 \) for all \( k \neq 0 \), satisfying this condition.

### Why Other Options Are Incorrect:
- **A. (ii) and (iv) only**: Excludes (i) and (iii), but both are true. The mean is zero, and autocovariances are constant over time.
- **B. (i) and (iii) only**: Excludes (ii) and (iv), but variance is constant and autocovariances are zero except at lag zero.
- **C. (i), (ii), and (iii) only**: Excludes (iv), but the zero autocovariance condition at non-zero lags is a defining feature of white noise.

All four properties (i)–(iv) are inherent to the definition of a white noise process, making **D** the correct answer.
[overthinking]
Okay, so I have this multiple-choice question about white noise processes, and I need to figure out why the correct answer is D, which says all four statements (i) through (iv) are correct. Let me start by recalling what a white noise process is. 

First, I remember that in time series analysis, a white noise process is a basic concept. The term "white noise" comes from signal processing, where it refers to a signal that has a constant power spectral density (so, all frequencies contribute equally). In statistics, though, it's a bit different. I think a white noise process has to satisfy certain statistical properties. Let me jot down what I know:

1. **Zero Mean**: I believe that for a white noise process, each individual observation has a mean of zero. So that would make statement (i) true. But wait, sometimes I've heard of "zero-mean white noise" versus just white noise. Maybe the term "white noise" by itself always includes zero mean? Hmm, need to confirm that.

2. **Constant Variance**: I think the variance is also a key part. Each term in the process should have the same variance. So that's a constant variance, which would make statement (ii) correct too. So (ii) is true.

3. **Autocovariances that are constant**: Wait, autocovariance at different lags. Wait a second, autocovariance is the covariance between two points in the series separated by a certain lag. For white noise, I think the autocovariance is zero except at lag zero. Because the process has no correlation between different time points. But the question says "autocovariances that are constant". Wait, if autocovariances are only non-zero at lag zero, then they aren't constant across all lags. Wait, maybe I misinterpret that. Let me think again.

Wait, perhaps statement (iii) is trying to trick me here. The autocovariance at lag 0 is the variance, which is constant (as per (ii)), and for other lags, it's zero, which is also constant? Wait, so autocovariance is constant across all lags except lag zero? No, actually, for all non-zero lags, it's zero, so the autocovariances are constant (they are all zero except at lag zero). Hmm, but the wording says "autocovariances that are constant". Maybe they mean that the autocovariance doesn't depend on the time index, but only on the lag. Wait, actually, in a white noise process, the autocovariance only depends on the lag, not the specific time points. That's a property of a weakly stationary process. Since white noise is a type of weakly stationary process, then its autocovariance depends only on the lag, making it constant for each lag. So (iii) is true? Wait, but the problem here is (iii) says "autocovariances that are constant", but actually, autocovariances are different at lag zero and non-zero lags, but they are constant across different time points for the same lag. Hmm, perhaps the wording is ambiguous here. Let me check definitions.

4. **Autocovariances that are zero except at lag zero**: This is definitely a key part of white noise. The autocovariance between different time points (lag ≠ 0) is zero. So (iv) is true.

Wait, so maybe the confusion is between (iii) and (iv). Let me rephrase the statements:

(iii) Autocovariances that are constant.

(iv) Autocovariances that are zero except at lag zero.

So, if (iii) is "constant", does that mean the autocovariance is the same for all lags? But in white noise, the autocovariance is constant for each lag in the sense that it's the same at lag k as it is at lag k at any time t, but actually, the autocovariance is different between lag 0 and others. Wait, maybe (iii) is referring to stationarity. Because a white noise process is a stationary process, so autocovariance depends only on the lag, not the time. So in that sense, for each lag, the autocovariance is constant over time. Therefore, statement (iii) is correct as well?

Hmm, this is a bit confusing. Let me look up the exact definitions to be sure.

From my notes: A white noise process is a sequence of uncorrelated random variables with mean zero and finite variance. So, if it's a white noise process, then each term has mean zero (so (i) is true), constant variance (so (ii) is true). The autocovariance between any two different times (i.e., lag ≠ 0) must be zero (so (iv) is true). Since autocovariance at lag 0 is variance, which is constant, so overall autocovariance function is only non-zero at lag zero, which is the variance. 

Therefore, the autocovariances are not "constant" in the sense of being the same for all lags, but they are "constant over time" in the sense that for any two points separated by a lag k, the autocovariance is the same, regardless of when you measure it. So the autocovariance only depends on the lag, not the time, which is the definition of covariance-stationary (weakly stationary) process. Therefore, (iii) says "autocovariances that are constant", which might be slightly ambiguous. Wait, maybe the question is using "constant" in the sense of being the same for all lags? But that would be incorrect, because only lag 0 has variance, others are zero. Alternatively, maybe "constant over time", which is true, so (iii) is correct.

Alternatively, perhaps "autocovariances that are constant" just means that the autocovariance function is constant for each lag, which is true. Since for any lag k, the autocovariance is the same at any time. So (iii) is correct.

Therefore, all four statements (i), (ii), (iii), (iv) are correct, so the answer is D.

Wait, but let me make sure. Let me check each statement again:

(i) A zero mean: Yes, by definition, white noise has mean zero at each point.

(ii) Constant variance: Yes, each term has the same variance, which is a requirement.

(iii) Autocovariances that are constant: Hmm. The autocovariance at lag k is the same for all t. Since the process is stationary, autocovariance depends only on k, so for any two points separated by k, the covariance is the same. So in that sense, yes, the autocovariances are constant over time (but they can differ between lags). So maybe the question is using "constant" in the sense of "does not depend on time", which is true. Therefore, (iii) is correct.

(iv) Autocovariances that are zero except at lag zero: Yes, that's exactly the definition. So (iv) is correct.

Therefore, all four statements are true, so D is correct. 

Wait, but maybe there's a nuance here. Let me think again. 

Is autocovariance at lag zero equal to variance? Yes. So that is constant (since variance is constant). The autocovariance for any other lag is zero. Therefore, the autocovariance function is a spike at lag 0 and zero elsewhere. So (iv) is true. 

But (iii) says autocovariances are constant. If "constant" is meant for each lag, then each autocovariance at a particular lag is constant over time. So, for example, the autocovariance at lag 1 is the same at all times. Since the process is stationary, that's true. So, (iii) is correct. 

Alternatively, if "constant" meant that all autocovariances are the same, then no, because lag 0 is variance, others are zero. But I think the former interpretation is correct. 

Hence, all four statements are correct. So answer D is correct.

**Final Answer**
\boxed{D}
</think>

A white noise process is characterized by several key properties in time series analysis. Let's analyze each statement:

1. **A zero mean (i):**  
   By definition, a white noise process has a mean of zero at each time point. This is a fundamental requirement, so statement (i) is true.

2. **A constant variance (ii):**  
   Each observation in a white noise process has the same variance, which is another essential property. Thus, statement (ii) is true.

3. **Autocovariances that are constant (iii):**  
   A white noise process is covariance-stationary (weakly stationary), meaning its autocovariance depends only on the lag between two points, not their specific time indices. Therefore, the autocovariance is constant over time for a given lag. This makes statement (iii) true in the context of stationarity.

4. **Autocovariances that are zero except at lag zero (iv):**  
   The defining feature of white noise is that observations are uncorrelated across different time points. This means the autocovariance is zero for any non-zero lag, while the autocovariance at lag zero (the variance) is constant. Hence, statement (iv) is true.

All four statements (i), (ii), (iii), and (iv) are correct, making the answer D.

\boxed{D}
[overthinking]
Okay, so I have this multiple-choice question about a white noise process. The question lists four statements, (i) to (iv), and asks which ones are correct. The options are A through D, with D being all four of them. The user is asking why the correct answer is D. Let me think through this step by step.

First, I need to recall what a white noise process is. From what I remember, a white noise process is a fundamental concept in time series analysis. The term "white noise" is borrowed from signal processing, where it refers to a signal with a flat power spectral density. In time series terms, a white noise process is a sequence of random variables with certain properties.

Let me try to list the properties of a white noise process. I think the key properties are that it has a constant mean, a constant variance, and that there's no autocorrelation between the terms except at lag zero. Wait, but I need to be precise here.

Starting with statement (i): A zero mean. Hmm. I believe that a white noise process typically has a mean of zero. But maybe the definition allows for a non-zero mean? Or is it required to have zero mean? Let me check my notes. Hmm, actually, sometimes the white noise is defined with zero mean, but maybe in some contexts, it's just a constant mean, not necessarily zero. Wait, the user is asking why the answer is D, which includes (i). So perhaps the standard definition requires a zero mean. Let me confirm that.

Looking up in my mind, the standard definition of a white noise process in time series is that it is a sequence of uncorrelated random variables with mean zero and finite variance. So yes, the mean must be zero. Therefore, (i) is correct.

Moving on to (ii): A constant variance. Since each term in the white noise process is a random variable, they must all have the same variance. That's part of the definition. The variance isn't allowed to change over time; it's constant. So (ii) is correct too.

Statement (iii): Autocovariances that are constant. Wait, hold on. Autocovariance here refers to the covariance between terms at different lags. But in a white noise process, the autocovariance at any non-zero lag should be zero, right? So how can autocovariances be constant except at lag zero? Wait, maybe I'm mixing up autocovariances and autocorrelation. Let me think again. Autocovariance at lag k is Cov(X_t, X_{t+k}). For white noise, since the variables are uncorrelated, this should be zero for all k ≠ 0. So the autocovariances themselves are zero except at lag zero. But the question says "autocovariances that are constant." Hmm, does that mean that the autocovariance function is constant across lags? That can't be, because at lag 0 it's the variance, and at other lags it's zero. Unless the wording is different.

Wait, maybe I misread the statement. Let me check again. (iii) says "autocovariances that are constant". But actually, the autocovariance at lag 0 is the variance, which is constant (due to ii), and the autocovariances at other lags are zero. So the autocovariances are zero for lags not zero, but is that considered "constant"? Hmm, perhaps the term "constant" here might be referring to the fact that the autocovariance function doesn't change over time, which is true because the process is stationary. Wait, maybe I need to consider stationarity.

Ah, right! For a white noise process, it is a weakly stationary process. Weak stationarity requires that the mean is constant (which we already have as zero), the variance is constant, and the autocovariances depend only on the lag, not on time. Since the autocovariances at any given lag are the same for all time points. So even though the autocovariance at lag k≠0 is zero, that zero is a constant value. So in that sense, the autocovariances are constant across time. Therefore (iii) is also correct.

But wait, the wording of (iii) is a bit confusing. Let me parse it again. The question says "(iii) Autocovariances that are constant". If "constant" here refers to autocovariances not depending on the time index, but only on the lag, then that's stationarity, which is true for white noise. So yes, it is constant over time. The autocovariance structure is time-invariant, so (iii) is correct.

Now, statement (iv): Autocovariances that are zero except at lag zero. That's exactly the property I was thinking earlier. The autocovariance between any two terms separated by a non-zero lag is zero, so only at lag zero (i.e., the variance) is it non-zero. So (iv) is also correct.

Therefore, all four statements (i) through (iv) are correct properties of a white noise process, so the answer is D.

Wait, but let me double-check each point again to be thorough.

First, (i): Zero mean. As per the standard definition of white noise in time series, yes, it's required to have a constant mean, often taken as zero. If it had a non-zero mean, you could subtract it to get a zero mean process, which is still white noise, so maybe sometimes the mean is just a constant μ, but in the strictest sense, the classical white noise is zero mean. Since the question doesn't specify, but the answer is D, so (i) must hold.

(ii) Constant variance: Since each term is identically distributed (as part of stationarity), their variances are the same, so yes, constant variance.

(iii) Autocovariances constant: As part of weak stationarity, autocovariances depend only on the lag, so over time they don't change. So they are constant in the sense that they don't vary with time, only with lag. So (iii) is correct.

(iv) Autocovariances zero except at lag zero: That's the key property of white noise. No correlation between different terms. So yes.

Therefore, all four are correct. The possible confusion might come if someone mistakes (iii) and (iv). Let me see if (iii) might be incorrectly referring to the autocovariances being constant across lags, which would not be true, because they are zero except at lag zero. But the question says "autocovariances that are constant", which is about time constancy, not lag. So (iii) is correct because autocovariance at lag k is the same for all t, hence constant over time.

Alternatively, if "constant" was meant across lags, then that would be incorrect, but that's not the standard interpretation. Therefore, the correct answer is D.

I think that's it. All four statements are indeed properties of a white noise process, so D is the right answer.
</think>

The correct answer is **D. (i), (ii), (iii), and (iv)** because all four statements accurately describe the properties of a white noise process:

1. **Zero Mean (i):** By definition, a white noise process has a constant mean, typically assumed to be zero. Even if a non-zero mean exists, it can be adjusted to zero by subtracting the mean (without affecting other properties like variance). Thus, the process is generally considered to have a zero mean.

2. **Constant Variance (ii):** The variance of each term in the process is constant over time. This is required for stationarity, which white noise inherently possesses (weak stationarity).

3. **Autocovariances That Are Constant (iii):** The autocovariance at any lag \( k \) depends only on \( k \), not on the time index \( t \). This time-invariance of autocovariances is a key aspect of weak stationarity. For example, the autocovariance at lag 0 is always the variance (a constant value), and autocovariances at all other lags are zero (also constant across time).

4. **Autocovariances Zero Except at Lag Zero (iv):** A defining characteristic of white noise is that its terms are uncorrelated. This means the autocovariance between observations separated by any lag \( k \neq 0 \) is zero. Only at lag zero (the variance) is the autocovariance non-zero.

### Key Clarifications:
- **Autocovariance vs. Lag:** The term "constant" in (iii) refers to autocovariances not changing over time (stationarity), not across different lags. The autocovariance at each lag is fixed (e.g., zero at non-zero lags and a constant variance at lag zero).
- **Zero Mean Requirement:** While some sources might allow a non-zero mean, the standard definition of white noise in time series assumes a zero mean. If the mean were non-zero, it could be subtracted to achieve zero mean without losing other properties.

Thus, all four statements (i)–(iv) are correct, making **D** the correct answer.
[overthinking]
Okay, let me try to figure out why the correct answer is D for this question about white noise processes. The question lists four statements, and I need to verify which ones are true. Let me start by recalling what a white noise process is. 

From what I remember in my time series class, a white noise process is a sequence of random variables that are uncorrelated, have a mean of zero, and constant variance. But I might be mixing up some details here. Let me break down each of the four statements one by one.

First, statement (i): "A zero mean." I think that's part of the definition. A white noise process is typically assumed to have a constant mean, often zero. So yeah, (i) should be true.

Statement (ii): "A constant variance." That also sounds right. Since the variance is the expectation of the squared deviation from the mean, and if each term in the process has the same variance, then it's constant. So (ii) is probably correct too.

Now statement (iii): "Autocovariances that are constant." Wait, autocovariances depend on the lag between terms, right? For a white noise process, the autocovariance at lag k (where k is not zero) should be zero because the terms are uncorrelated. But the autocovariance at lag zero is just the variance. Since the variance is constant (as per statement ii), then the autocovariance at lag zero is constant. However, autocovariances at other lags are zero. Hmm, so is autocovariance being "constant" referring to being the same across all lags? Wait no, autocovariance function usually depends on the lag. So maybe (iii) is not correct. Wait, but hold on, maybe the question is phrased as "constant" in the sense that the variance doesn't change over time? Wait, the variance is part of the autocovariance at lag zero. If the variance is constant, then the autocovariance at lag zero is constant. But autocovariance at other lags are zero. So maybe the autocovariances are not constant across all lags, but the variance is constant. Maybe I need to clarify.

Wait, let me think again. Autocovariance function is a function of the lag. For a white noise process, the autocovariance at lag 0 is the variance, which is constant. At any non-zero lag, it's zero. So the autocovariance function is not constant across all lags, except for being zero at all non-zero lags. But maybe the question is referring to the autocovariance being independent of time, which they are. Since the process is stationary, the autocovariance only depends on the lag, not the time. So maybe (iii) is correct because the autocovariances are constant over time, even though they vary with lag. Wait, the wording is a bit ambiguous. Let me check the exact definition.

In time series, a white noise process is weakly stationary, meaning that it has constant mean, constant variance, and autocovariances that depend only on the lag and not on time. So the autocovariances are constant over time for a given lag. Since they are zero except at lag zero, but that's still "constant" in the sense that for each lag, the autocovariance is the same at any time point. So statement (iii) would be true because autocovariances are constant over time, not varying with time. Therefore, (iii) is correct.

Then statement (iv): "Autocovariances that are zero except at lag zero." That's exactly the property of white noise. The autocovariance is non-zero only at lag 0 (which is the variance), and zero otherwise. So (iv) is definitely true.

Wait, but if (iii) and (iv) are both true, then all four statements would be correct, making D the answer. Let me check again each point.

(i) Zero mean: Yes, standard white noise is defined with mean zero. Though sometimes it might just say constant mean, but usually it's zero. The question didn't specify, but the options include (i) as a separate condition, so assuming that (i) is required. Since the question includes (i) as an option, and the answer is D, they must mean that (i) is true.

(ii) Constant variance: Yes, since it's a white noise process, variance is constant.

(iii) Autocovariances that are constant: Since the autocovariance at any lag h is the same at any point in time. Because the process is stationary, autocovariances depend only on h, not on time t. So the autocovariances are "constant" in the sense that they don't change over time, which is what stationarity implies. So (iii) is correct.

(iv) Autocovariances zero except at lag zero: Exactly the definition of white noise. So (iv) is correct.

Therefore all four statements are true, so the answer is D.

Wait but maybe I made a mistake with (iii). Let me confirm. The autocovariance function for a white noise process is Cov(X_t, X_{t+h}) = 0 for h ≠ 0, and Var(X_t) for h=0. Since the variance is constant over time (because the process is stationary), so the autocovariances are indeed constant over time. The autocovariance at lag h is the same at any t. Therefore, the autocovariances are constant (in time), so (iii) is correct. So all four statements hold, so D is correct. Got it.

Another way someone might get confused is if they thought "constant variance" and "autocovariances constant" are the same, but they are different aspects. The variance is the autocovariance at lag 0, and the autocovariances at other lags are zero. So (ii) talks about variance being constant, (iii) talks about autocovariances (all of them) being constant over time (i.e., not depending on t, only on h), and (iv) specifies that the autocovariances are zero except at lag zero. Therefore, all four are correct.

Yes, that makes sense. So the answer is D.
</think>

The correct answer is **D. (i), (ii), (iii), and (iv)**. Here's why each statement holds for a white noise process:

1. **(i) A zero mean**:  
   A white noise process is typically defined as having a constant mean, and by convention, this mean is often assumed to be **zero** (unless otherwise specified). Thus, the first statement is true.

2. **(ii) A constant variance**:  
   The variance of each term in the white noise process is **constant over time** (a property of stationarity). This aligns with the requirement that the process has no trends or seasonal changes in its spread. Hence, the second statement is also true.

3. **(iii) Autocovariances that are constant**:  
   Autocovariances depend only on the **lag** (difference in time periods) and not on the actual time points. For a white noise process, the autocovariance at lag \( h \neq 0 \) is **zero**, and at lag \( h = 0 \), it is equal to the constant variance. Since autocovariances do not change over time (they are purely functions of lag), they are "constant" in the sense of being time-invariant. Thus, (iii) is true.

4. **(iv) Autocovariances that are zero except at lag zero**:  
   This is the defining characteristic of white noise. The process has **no correlation** between observations at different times (\( h \neq 0 \)), so all autocovariances except at lag zero are **zero**. The autocovariance at lag zero is the variance (non-zero but constant). Therefore, (iv) is true.

### Why Not Other Options?
- **Option A (ii and iv only)**: Incorrect because (i) and (iii) are also true.
- **Option B (i and iii only)**: Incorrect because (ii) and (iv) are true.
- **Option C (i, ii, iii only)**: Incorrect because (iv) is also true.
- **Option D (all four)**: Correct because all statements align with the properties of a white noise process.

### Key Takeaway:
A white noise process satisfies **strict stationarity** with **zero correlation** between observations at different times, a **constant mean** (often zero), and a **constant variance**. These properties make statements (i)–(iv) all true.
[overthinking]
Okay, so I have this question about white noise processes, and I need to figure out why the correct answer is D, which says all four statements (i) through (iv) are correct. Let me start by recalling what a white noise process is. From what I remember, a white noise process is a basic concept in time series analysis. It's a sequence of random variables that are uncorrelated and have the same variance. But wait, I should be precise here. Let me go through each of the statements one by one.

First, statement (i): A white noise process will have a zero mean. Hmm, I think that's part of the definition. If I recall correctly, a white noise process is usually defined as a series of independent and identically distributed (iid) random variables with mean zero and constant variance. So yes, the mean is zero. But wait, sometimes the mean might not have to be zero? Or is that a requirement? Let me check my notes. Oh right, actually, some sources might define white noise more generally as having a constant mean, which could be zero or non-zero, but the standard definition, especially in econometrics, typically assumes a zero mean. Hmm, but maybe the question here is considering the standard case where the mean is zero. Since the answer options include (i), and the correct answer is D, then it must require the zero mean. So I'll go with that. So (i) is correct.

Moving on to (ii): A constant variance. That I'm more confident about. Since white noise has identical distribution, each term should have the same variance. So variance is constant, so (ii) is correct.

Statement (iii): Autocovariances that are constant. Wait a second, autocovariance at different lags? Wait, in a white noise process, the autocovariance between two points at different times should be zero, except when the lag is zero. Wait, but if autocovariances are constant, that might not be the case. Let me think. The autocovariance function for a white noise process is actually zero for all non-zero lags. So the autocovariance isn't constant across lags, except that it's zero for all non-zero lags. Wait, the autocovariance is only non-zero at lag zero, which would be the variance. So the autocovariance at lag zero is the variance, and all others are zero. So autocovariances are not constant across all lags, but they are zero except at lag zero. Wait, but the question says "autocovariances that are constant". Maybe that's a misstatement? Or maybe in the sense that the autocovariance function is constant over time, but not over lags? Hmm, perhaps I need to parse this more carefully.

Alternatively, maybe (iii) is referring to the autocovariance of the process being the same at each lag, which it's not except for lag zero. Wait, perhaps the term "constant" here might be confusing. Alternatively, maybe "autocovariances that are constant" refers to the autocovariance function being time-invariant, which it is, because white noise is a stationary process. So if the process is stationary, then the autocovariances depend only on the lag and not on time, so in that sense, they are constant over time. So perhaps (iii) is correct because the autocovariances are constant over time, even though they vary across different lags. Wait, but the question says "autocovariances that are constant"—maybe the wording is a bit ambiguous. Let me think again. 

Wait, in the definition of stationarity, specifically weak stationarity, the autocovariance depends only on the lag, so for a white noise process, the autocovariance at lag k is zero for any k ≠ 0, and the variance at lag 0. Since the variance is constant, the autocovariances are "constant" in the sense that they don't depend on time t, only on the lag. So in that case, statement (iii) would be correct, because for any two time points separated by the same lag, the autocovariance is the same, so they are constant over time. So (iii) is correct.

Then statement (iv): Autocovariances that are zero except at lag zero. That's the key property of white noise. Since the terms are uncorrelated, the covariance between any two different terms (different lags) is zero. The covariance at lag zero is just the variance. So this is definitely true. Therefore, (iv) is correct.

Wait, so if all four statements (i) through (iv) are correct, then the answer is D. But let me verify again because sometimes there's a nuance.

Wait, maybe I made a mistake with (iii). Let me think again. If the autocovariances at different lags are different, then they aren't constant across lags. But the question says "autocovariances that are constant". Wait, maybe "constant" here refers to time constancy, not across lags. Since the autocovariance function does not depend on time, only on the lag, that's part of being covariance-stationary. So the autocovariances are constant over time, so (iii) is correct. So the wording of (iii) is a bit tricky but it's correct.

Alternatively, if someone interprets (iii) as autocovariances being the same for all lags, that would be wrong. But that's not what the question is saying. The wording is "autocovariances that are constant"—probably meaning over time. Since the process is stationary, yes, autocovariances are constant over time. So (iii) is okay.

So then (i) zero mean, (ii) constant variance, (iii) autocovariances constant over time (stationary), (iv) autocovariances are zero except lag zero. Therefore, all four are correct, so D is the answer.

But wait, let me check again if white noise requires zero mean. The strict definition of white noise is indeed zero mean, constant variance, and autocovariance zero for non-zero lags. So (i) and (iv) are required. The variance is constant, so (ii). And because it's stationary, the autocovariances depend only on lag, so (iii) is also correct. Therefore, D is correct.

Another way to check: let's see if there is a case where one of these is not true. For example, if the process had a non-zero mean, then (i) would be false, but since it's white noise, the mean is zero. The variance is constant. The autocovariance is only non-zero at lag zero, so (iv) holds, and the autocovariances are constant over time (stationary). So all four are correct. Therefore, D is correct.

**Final Answer**
\boxed{D}
</think>

A white noise process is defined as a sequence of uncorrelated random variables with a constant mean, constant variance, and autocovariances that are zero except at lag zero. Let's analyze each statement:

1. **A zero mean (i):** A white noise process is typically defined to have a zero mean. This is a fundamental property of white noise, so this statement is correct.

2. **A constant variance (ii):** The variance of each term in a white noise process is constant, which is another key property. This statement is correct.

3. **Autocovariances that are constant (iii):** Autocovariances in a white noise process depend only on the lag and not on time, which is a requirement for a stationary process. Since the autocovariance function is time-invariant, this statement is correct in the sense that autocovariances are constant over time.

4. **Autocovariances that are zero except at lag zero (iv):** By definition, the autocovariance between terms at different lags (non-zero lags) is zero. The only non-zero autocovariance is at lag zero, which is the variance. This statement is correct.

All four statements (i), (ii), (iii), and (iv) are correct, making the correct answer:

\boxed{D}
[overthinking]
Okay, let me try to figure out why the correct answer is D for this question about a white noise process. Hmm, first, I need to recall what a white noise process is. From what I remember in my time series class, white noise is a fundamental concept. Let me go through each of the statements (i) to (iv) one by one to see which are true.

Starting with statement (i): "A zero mean." I think white noise is defined as having a constant mean, and usually that constant is zero. So yeah, the mean is zero. That should be correct. So (i) is true.

Statement (ii): "A constant variance." Variance being constant over time is part of the definition too. Because if the variance changes, it's not stationary, and white noise is a stationary process. So variance σ² is constant for all time points. So (ii) is also true.

Moving on to (iii): "Autocovariances that are constant." Wait, autocovariances... Hmm. Autocovariance at lag k is the covariance between the process at time t and t + k. For a white noise process, since it's covariance-stationary, the autocovariances only depend on the lag k and not on t. So they should be constant over time. So (iii) is correct. Wait, but actually, hold on. The autocovariance function is a function of the lag, so they are constant for each lag. But does that mean that the autocovariances themselves are constant? Or that they don't depend on t? Maybe I need to clarify here. The autocovariance at lag 0 is the variance, which is constant. The autocovariance at any non-zero lag should be zero. Wait, but the question says "autocovariances that are constant". Since the autocovariance at any specific lag is a constant (either σ² at lag 0 or 0 otherwise), so yes, they are constant across different lags in terms of being either σ² or 0. But maybe the wording here is tricky. The question says "autocovariances that are constant". Since for any two different lags, their autocovariances are different (either 0 or σ²), but for a fixed lag, it's constant. Hmm, maybe the question is referring to the autocovariance not depending on time, so they are constant over time. Since the process is stationary, autocovariances don't depend on t. So (iii) is correct. So yes, (iii) is true.

Statement (iv): "Autocovariances that are zero except at lag zero." That's the key property of white noise, right? The autocovariance is σ² at lag 0 and zero for all other lags. So yes, that's exactly the definition. So (iv) is also true.

Wait, but hold on. Let me make sure there's no confusion here. The problem says "autocovariances that are constant" (iii) and "autocovariances that are zero except at lag zero" (iv). So (iii) is about stationarity (autocovariances depending only on lag, not time), and (iv) is about the specific form of the autocovariance function (zero except at lag zero). So if all four statements are correct, then D would be the answer. But let me verify each one again.

White noise definition: A white noise process is a sequence of uncorrelated random variables with mean zero and constant variance. So, (i) zero mean, (ii) constant variance, (iii) autocovariances depend only on the lag (so they are constant over time, hence stationary, so (iii) is true), and (iv) the autocovariance is zero except at lag zero. So all four statements are correct, so D should be the answer. 

Wait, but I need to check if perhaps autocovariances being "constant" is a misinterpretation. For example, if they are saying that autocovariances are the same for all lags, which isn't true because at lag 0 it's variance, and others are zero. But the question says "autocovariances that are constant", not that all autocovariances are the same. The term "constant" here probably means they don't change over time, which is true for a stationary process, which white noise is. So (iii) is correct.

Alternatively, maybe someone could misinterpret (iii) as all autocovariances are the same, but that's not what it says. The wording is "autocovariances that are constant", which in time series terms refers to stationarity, meaning they depend only on the lag, not on time. So yes, (iii) is correct.

Therefore, all four statements (i) through (iv) are correct, so the answer is D. That makes sense. Let me just cross-verify with the definitions.

Looking up white noise: According to time series textbooks, a white noise process is indeed a sequence of uncorrelated random variables with zero mean and finite variance. The term "white" comes from the fact that all frequencies are equally present in terms of variance, and "noise" refers to the random component. The key properties are:

1. Constant mean (which is typically taken as zero in most definitions).
2. Constant variance.
3. No autocorrelation at any lag except lag zero (so autocovariances are zero except at lag zero).
4. The process is covariance-stationary, so autocovariances depend only on lag, hence they are constant over time (so (iii) is just a restatement of stationarity).

Hence, all four properties are indeed true for white noise. Therefore, the correct answer is D.
</think>

The correct answer is **D. (i), (ii), (iii), and (iv)**. Here's the breakdown:

1. **Zero Mean (i):**  
   A white noise process is defined as having a **constant mean**, which is typically assumed to be **zero**. This satisfies condition (i).

2. **Constant Variance (ii):**  
   The variance of a white noise process must be **constant over time**, denoted as \(\sigma^2\). This ensures the process is stationary, fulfilling condition (ii).

3. **Autocovariances That Are Constant (iii):**  
   White noise is **covariance-stationary**, meaning its autocovariances depend only on the lag (\(k\)) and not the time (\(t\)). For any fixed lag \(k\), the autocovariance is constant over time. Thus, (iii) is true.

4. **Autocovariances Zero Except at Lag Zero (iv):**  
   The defining feature of white noise is that **autocovariances are zero for all lags \(k \neq 0\)**. At lag zero, the autocovariance equals the variance (\(\sigma^2\)), satisfying (iv).

### Why Other Options Are Incorrect:
- **A. (ii) and (iv) only**: Incorrect because (i) and (iii) are also true.
- **B. (i) and (iii) only**: Incorrect because (ii) and (iv) are also true.
- **C. (i), (ii), and (iii) only**: Incorrect because (iv) is true as well.

### Key Takeaway:
A white noise process is characterized by **zero mean**, **constant variance**, **stationarity** (constant autocovariances over time), and **no autocorrelation** except at lag zero. All four properties hold, making **D** the correct choice.
[overthinking]
Okay, so I have this question about a white noise process and which of the statements (i) through (iv) are true. The answer is supposed to be D, which says all four are correct. But let me go through each of them one by one to make sure I understand why each is true. 

First, what is a white noise process? I remember that in time series analysis, white noise is a basic concept. It's like the simplest form of a stationary process. The term "white noise" is borrowed from signal processing, where it's a signal with equal power at all frequencies. In statistics, a white noise process has three key properties: it has a constant mean, constant variance, and no autocorrelation between different time points. That last part probably relates to the autocovariances. 

Let me recall the formal definition. A white noise process, often denoted as {ε_t}, is a sequence of uncorrelated random variables each with mean zero and finite variance. So, if it's a white noise process, the mean is indeed zero, so statement (i) "A zero mean" should be true. 

Then, the variance is constant. Since each term in the process has the same variance, that's a key feature. So (ii) "A constant variance" must be correct as well. 

Now, autocovariances. Autocovariance at lag k is the covariance between ε_t and ε_{t+k}. Since the process is white noise, the variables are uncorrelated at any non-zero lag. That means the autocovariance should be zero for any lag not equal to zero. At lag zero, it's just the variance. So statement (iv) says "Autocovariances that are zero except at lag zero," which is exactly that. So (iv) is definitely true. 

But what about (iii): "Autocovariances that are constant." Wait, does that make sense? Autocovariances at the same lag should be the same across different times? Hmm. Wait, maybe I need to think about stationarity here. A white noise process is a specific type of stationary process, called weakly stationary or covariance stationary. For a process to be stationary, the mean is constant (so (i) is part of that), the variance is constant (so (ii) is also part of stationarity), and the autocovariance depends only on the lag k and not on time t. 

Therefore, the autocovariance function γ(k) is the same for all t. Since in white noise, for k ≠ 0, the autocovariance is zero, and for k = 0, it's the variance. Therefore, the autocovariances are indeed constant over time for each lag. Wait, but the autocovariances themselves: the value of the autocovariance at any particular lag is constant. For example, γ(1) is the autocovariance at lag 1, which is zero, and that's the same for all t. Similarly, γ(2) is zero as well. So the autocovariances (the values of γ(k)) are constant for each lag. Therefore statement (iii) is also true? Wait, but the wording is a bit confusing. 

Wait, the question says "Autocovariances that are constant." Maybe that could be interpreted as the autocovariance doesn't change with the lag? No, that wouldn't make sense. Or does it mean that the autocovariance at a given lag is constant over time? Since the process is stationary, the autocovariance at lag k is the same for all t. So, in that case, (iii) is true. Alternatively, maybe (iii) is trying to trick us because the autocovariances only take on two values: zero for lags ≠0 and the variance at lag 0. But "constant" here probably refers to the autocovariance at a given lag being constant over time, which they are because of stationarity. 

So, putting this all together: 

(i) Zero mean – yes, part of the definition.

(ii) Constant variance – yes, also part of the definition.

(iii) Autocovariances that are constant? Since autocovariances depend only on the lag and not on time, so yes, they are constant over time for each lag. So (iii) is true.

(iv) Autocovariances zero except at lag zero – yes, that's the uncorrelatedness part of white noise.

Therefore all four statements are correct, so the answer is D.

Wait, but maybe I'm mixing up something here. Let me verify (iii) again. The autocovariance function for white noise is γ(k) = σ² when k=0 and 0 otherwise. So, the autocovariances (the values) are constants, not varying with time. So in that sense, they are constant. If the autocovariances were changing over time, then they wouldn't be constant, but since the process is stationary, they are. Therefore, (iii) is true. 

Another way: The autocovariance at lag k is the same for all t. So for any t, Cov(ε_t, ε_{t+k}) = γ(k), which is a constant. Therefore, the autocovariances are indeed constant. Therefore (iii) is correct.

So all four statements (i), (ii), (iii), (iv) are true, so the answer must be D. 

But let me check the options again:

A. (ii) and (iv) only. That can't be, since (i) is true.

B. (i) and (iii) only. Then (ii) and (iv) are excluded, but both are true.

C. (i), (ii), and (iii) only. But (iv) is also true.

D. All four. So yes, D is the correct answer.

Therefore, the correct answer is D.

**Final Answer**
\boxed{D}
</think>

A white noise process is a fundamental concept in time series analysis, characterized by three key properties: a constant mean, constant variance, and no autocorrelation between different time points. Here's the detailed breakdown of why all four statements (i) to (iv) are true:

1. **Zero Mean (i):** By definition, a white noise process has a mean of zero. This is a crucial component of the process's definition, making statement (i) true.

2. **Constant Variance (ii):** Each term in a white noise process has the same variance, which is a finite and constant value. This confirms that statement (ii) is true.

3. **Autocovariances that are constant (iii):** A white noise process is a type of weakly stationary process. For a stationary process, the autocovariance depends only on the lag \( k \) and not on time \( t \). Since the autocovariance at any lag \( k \) is constant over time, statement (iii) is true.

4. **Autocovariances that are zero except at lag zero (iv):** The defining feature of white noise is that the variables are uncorrelated at any non-zero lag. This means the autocovariance is zero for all lags \( k \neq 0 \), and equal to the variance at lag zero. Thus, statement (iv) is also true.

Each of these statements aligns with the properties of a white noise process, confirming that all four are correct. Therefore, the correct answer is:

\boxed{D}
[overthinking]
Okay, so I need to figure out why the correct answer is D for this question about white noise processes. Let me start by recalling what a white noise process is. From what I remember in my stats class, a white noise process is a basic time series model where the data points are a sequence of uncorrelated random variables with zero mean and constant variance. But maybe I should break it down more carefully.

The question lists four statements:

(i) A zero mean

(ii) A constant variance

(iii) Autocovariances that are constant

(iv) Autocovariances that are zero except at lag zero.

The options are combinations of these, and the correct answer is D, which includes all four. Hmm. Let me go through each statement one by one.

Starting with (i), a zero mean. From my notes, a white noise process is typically defined as having a mean of zero. So that's probably true. The process is supposed to have no trend or drift, so the mean at every time point should be zero. So (i) is correct.

(ii) A constant variance. Yeah, that's another key property. The variance doesn't change over time; that's part of the definition. So each term in the series has the same variance. So (ii) is also correct.

(iii) Autocovariances that are constant. Wait, autocovariance at different lags. Wait, autocovariance function for a time series measures the covariance between two points separated by a certain lag. For white noise, the autocovariance at lag k (where k is not zero) should be zero, right? Because the variables are uncorrelated. So maybe the autocovariance is only non-zero at lag zero, which is the variance. Wait, so maybe (iii) is not correct? Wait, the question says "autocovariances that are constant". Hmm, maybe I need to parse this carefully.

Wait, autocovariance at lag 0 is the variance, which is constant (so that's okay). For lags other than zero, the autocovariance is zero. But the term "autocovariances that are constant" could be ambiguous. Are the autocovariances (for all lags) constant over time? Well, in a white noise process, the autocovariance doesn't depend on time, only on the lag. Since the process is stationary, autocovariances depend only on the lag. Therefore, they are constant over time. Wait, but (iii) says "autocovariances that are constant". If they are the same for all lags, then that's not true because at lag 0 it's variance and at other lags it's zero. But maybe the question is phrased as "autocovariances that are constant over time", but I think the question is just saying that autocovariances are constant, not varying with time. Since the process is stationary, all autocovariances depend only on the lag, so they are constant over time. So maybe (iii) is correct. Hmm, so (iii) is true?

Wait, but the wording is a bit confusing. Let me think again. For a white noise process, the autocovariance function is γ(k) = σ² if k=0 and 0 otherwise. So the autocovariances are either σ² or 0, depending on the lag. So they are not constant across different lags. But if the question is saying that for each lag, the autocovariance is constant over time, then that's true because of stationarity. So maybe the question is using "constant" in the sense that they don't change over time. Since white noise is a stationary process, all autocovariances at a given lag are constant over time. So (iii) is true. I think that's the case here.

(iv) Autocovariances that are zero except at lag zero. That's exactly what I just thought. The autocovariance is zero for all lags except zero, where it's equal to the variance. So (iv) is also correct.

Therefore, all four statements (i), (ii), (iii), and (iv) are true. So the answer is D. Wait, but I initially thought maybe (iii) is incorrect because autocovariances aren't the same across all lags. But actually, the autocovariances are constant over time for each lag, so they are constant in the sense of being time-invariant. So (iii) is correct. Therefore, D is indeed the right answer.

Let me cross-verify with the definition. A white noise process is a sequence of uncorrelated random variables with mean zero and finite variance. So (i) and (ii) are directly part of the definition. The autocovariance function is zero at all non-zero lags (so (iv)), and since the process is stationary, autocovariances depend only on the lag, hence they are constant over time (so (iii)). So all four are correct. The key is understanding that (iii) refers to stationarity, meaning autocovariances don't change over time, not that they are the same for all lags. Since the autocovariance at lag 0 is constant over time (the variance) and autocovariances at other lags are zero and also constant over time, (iii) holds. Got it. So the answer is D.
</think>

The correct answer is **D. (i), (ii), (iii), and (iv)** because all statements are true for a white noise process. Here's the breakdown:

1. **Zero Mean (i):** By definition, a white noise process has a constant mean of zero at all time points.  
2. **Constant Variance (ii):** The variance of each term in the process is constant over time (homoscedasticity).  
3. **Autocovariances Constant Over Time (iii):** Since a white noise process is **stationary**, its autocovariance depends only on the lag \( k \) and not on time \( t \). Thus, the autocovariances are constant across all time points for a given lag.  
4. **Autocovariances Zero Except at Lag Zero (iv):** The defining characteristic of white noise is **uncorrelatedness**, meaning autocovariances at all non-zero lags (\( k \neq 0 \)) are zero. The autocovariance at lag zero is simply the variance (non-zero).  

### Clarifying Ambiguities:
- **Statement (iii):** The phrase "autocovariances that are constant" refers to their **time-invariance**, not uniformity across all lags. Because the process is stationary, autocovariances for a fixed lag do not change over time (e.g., \( \text{Cov}(x_t, x_{t+k}) \) is the same for all \( t \)).  
- **Autocorrelation vs. Uncorrelatedness:** While autocovariances differ between lag 0 (variance) and other lags (zero), this distinction is captured by statement (iv) and does not contradict (iii).  

Thus, all four properties hold, making **D** the correct answer.
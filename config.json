{
    "models":[
        "/root/project/models/DeepSeek-R1-Distill-Llama-8B",
        "/root/project/models/DeepSeek-R1-Distill-Qwen-14B",
        "/root/project/models/QwQ-32B",
        "/root/project/models/Llama-3.1-8B",
        "/root/project/models/Qwen2.5-Math-7B-PRM800K",
        "deepseek-reasoner",
        "deepseek-chat"
    ],
    "api_key":"sk-a3b9a9c7bca646e294bface941734d47",
    "model_id":1,
    "max_reflect":10,
    "logprobs":20,
    "top-k":5,
    "top-p":0.99,
    "temperature":1,
    "max_model_len":8192,
    "gpu_memory_utilization":0.95,
    "gpu":"2",
    "batch_size":1,
    "times":5
}